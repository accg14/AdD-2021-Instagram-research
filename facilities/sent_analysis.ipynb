{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28053f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "458d97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/accg14/Documents/FIng/Taller ARS/Entrega/AdD-2021-Instagram-research/crossfitdelsur/crossfitdelsur.json'\n",
    "\n",
    "UNWANTED_CHARS = ['!', ',', '\"', '-', '...','‚Äì','XD', 'xD', '¬ø', '?', '‚Äî', '\\n', \"#\", '¬°', ':', \"‚Äú\", '.', '(', ')',\"¬¨¬¨\", \"\\('.')/\", \"*\", '\\n', '¬ª', '\\x97', '\\x85']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbef34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_comments(file):\n",
    "    with open(file) as json_file:\n",
    "        institute_posts = json.load(json_file)\n",
    "        for posts in institute_posts['GraphImages']:\n",
    "            comments_data = posts['comments']\n",
    "            for comment_data in comments_data['data']:\n",
    "                yield(comment_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04264a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "for comment in get_posts_comments(file):\n",
    "    comments.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c189dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcaf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(comment):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U000024C2-\\U0001F251\"\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', comment)\n",
    "\n",
    "def clean_comment(comment):\n",
    "    comment = remove_emoji(comment)\n",
    "    for char in UNWANTED_CHARS:\n",
    "        comment = comment.replace(char, ' ')\n",
    "        comment = re.sub('@\\w*', '', comment)\n",
    "        comment = re.sub('\\$', ' ', comment)\n",
    "        comment = comment.split(\" \")\n",
    "        comment = [token for token in comment if token != '']\n",
    "        return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff879a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(map(clean_comment, comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258c19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = list(filter(lambda x: len(x)>0, comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8553f158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Deseando', 'volver'],\n",
       " ['Ojal√°'],\n",
       " ['Ojal√°', 'Todos', 'queremos', 'volver'],\n",
       " ['Si', 'Por', 'favor'],\n",
       " ['3', 'minutos', 'en', 'esa', 'posici√≥n', 'seguro'],\n",
       " ['Mucho'],\n",
       " ['Much√≠simo', 'se', 'extra√±an', 'las', 'clases', 'y', 'su', 'gente'],\n",
       " ['Se', 'e', 'xtra√±a', 'la', 'gente,', 'pero', 'volveremos'],\n",
       " ['Ah√≠', 'estaremos', 'Pronto'],\n",
       " ['Es', 'a', 'dar', 'Sigo', 'tus', 'pasos', 'ü§£'],\n",
       " ['despegado'],\n",
       " ['Vamo', 'y', 'vamoooo', 'Siempre', 'apoyando', 'y', 'en', 'movimiento'],\n",
       " ['Crack'],\n",
       " ['Genios', 'All√°', 'vamos', 'Ma√±ana', '7am'],\n",
       " ['Grande', 'Javi'],\n",
       " ['7', 'am', 'vamos'],\n",
       " ['Vamo', 'arriba'],\n",
       " ['Vamo',\n",
       "  'arriba',\n",
       "  'Javi',\n",
       "  'Estaremos',\n",
       "  'firmes',\n",
       "  'como',\n",
       "  'rulo',\n",
       "  'de',\n",
       "  'estatua'],\n",
       " ['...',\n",
       "  'y',\n",
       "  'seguir√°n',\n",
       "  'teniendo',\n",
       "  'el',\n",
       "  'apoyo',\n",
       "  'de',\n",
       "  'la',\n",
       "  'comunidad,',\n",
       "  'Abrazo',\n",
       "  'grande',\n",
       "  'a',\n",
       "  'todos',\n",
       "  'y',\n",
       "  'a',\n",
       "  'seguir',\n",
       "  'empujando',\n",
       "  \"pa'delante\",\n",
       "  'CrossfitDelSur'],\n",
       " ['Grandes', 'Genial', 'iniciativa'],\n",
       " ['Chicos',\n",
       "  'Pueden',\n",
       "  'poner',\n",
       "  'link',\n",
       "  'al',\n",
       "  'canal',\n",
       "  'de',\n",
       "  'YouTube?',\n",
       "  'Me',\n",
       "  'estar√≠a',\n",
       "  'costando',\n",
       "  'encontrarlo'],\n",
       " ['Que', 'tremendo', 'ü§©'],\n",
       " ['Excelente,',\n",
       "  'a',\n",
       "  'mi',\n",
       "  'me',\n",
       "  'paso',\n",
       "  'eso.',\n",
       "  'Mismo,',\n",
       "  'y',\n",
       "  'estoy',\n",
       "  'mas',\n",
       "  'Q',\n",
       "  'agradecida'],\n",
       " ['Por',\n",
       "  'suerte',\n",
       "  'en',\n",
       "  'esos',\n",
       "  'procesos',\n",
       "  'y',\n",
       "  'caidas',\n",
       "  'est√°n',\n",
       "  'uds',\n",
       "  'para',\n",
       "  'sostenernos',\n",
       "  'y',\n",
       "  'recordarnos',\n",
       "  'que',\n",
       "  'si',\n",
       "  'se',\n",
       "  'puede'],\n",
       " ['Es',\n",
       "  'parte',\n",
       "  'del',\n",
       "  'camino,',\n",
       "  'no',\n",
       "  'importa',\n",
       "  'cuantas',\n",
       "  'veces',\n",
       "  'quedes',\n",
       "  'de',\n",
       "  'rodillas,',\n",
       "  'importa',\n",
       "  'la',\n",
       "  'veces',\n",
       "  'que',\n",
       "  'te',\n",
       "  'levantas',\n",
       "  'y',\n",
       "  'que',\n",
       "  'sea',\n",
       "  'Rock'],\n",
       " ['Feliz', 'd√≠a', 'a', 'las', 'chicas', 'crofiters'],\n",
       " ['Gracias', 'sure√±as', 'fuertes', 'y', 'bellas'],\n",
       " ['Vero', 'la', 'rompe'],\n",
       " ['Dos', 'grandes', 'de', 'Crossfit', 'del', 'Sur'],\n",
       " ['El',\n",
       "  'mejor',\n",
       "  'lugar',\n",
       "  'del',\n",
       "  'mundo',\n",
       "  'con',\n",
       "  'los',\n",
       "  'mejores',\n",
       "  'profesionales',\n",
       "  'infinitas',\n",
       "  'gracias',\n",
       "  'siempre'],\n",
       " ['Me',\n",
       "  'podr√≠an',\n",
       "  'pasar',\n",
       "  'costos',\n",
       "  'y',\n",
       "  'horarios',\n",
       "  'por',\n",
       "  'privado?',\n",
       "  'Gracias'],\n",
       " ['Saludos,',\n",
       "  'equipo',\n",
       "  'Hemos',\n",
       "  'tenido',\n",
       "  'la',\n",
       "  'oportunidad',\n",
       "  'de',\n",
       "  'ver',\n",
       "  'su',\n",
       "  'perfil',\n",
       "  'y',\n",
       "  'nos',\n",
       "  'encanta',\n",
       "  'su',\n",
       "  'concepto',\n",
       "  'de',\n",
       "  'entrenamiento',\n",
       "  'y',\n",
       "  'trabajo',\n",
       "  'en',\n",
       "  'el',\n",
       "  'gimnasio',\n",
       "  'Los',\n",
       "  'felicitamos',\n",
       "  'Les',\n",
       "  'hemos',\n",
       "  'dejado',\n",
       "  'un',\n",
       "  'mensaje',\n",
       "  'en',\n",
       "  'su',\n",
       "  'bandeja',\n",
       "  'de',\n",
       "  'entrada',\n",
       "  'con',\n",
       "  'una',\n",
       "  'propuesta',\n",
       "  'e',\n",
       "  'informaci√≥n',\n",
       "  'muy',\n",
       "  'interesante.',\n",
       "  'Estamos',\n",
       "  'seguros',\n",
       "  'que',\n",
       "  'les',\n",
       "  'gustar√°',\n",
       "  'Los',\n",
       "  'invitamos',\n",
       "  'a',\n",
       "  'leerla'],\n",
       " ['Dm', 'us'],\n",
       " ['Love', 'it', 'DM'],\n",
       " ['Love', 'it', ',', 'DM'],\n",
       " ['La', 'paz', 'no', 'es', 'opci√≥n'],\n",
       " ['Vamo', 'arriba', 'feliz', 'a√±o'],\n",
       " ['Feliz', 'a√±o'],\n",
       " ['Feliz', 'navidad', 'para', 'todos'],\n",
       " ['Muy', 'feliz', 'navidad', 'para', 'todos'],\n",
       " ['Lo',\n",
       "  'mejor',\n",
       "  'de',\n",
       "  'lo',\n",
       "  'mejor',\n",
       "  'en',\n",
       "  'esta',\n",
       "  'Navidad',\n",
       "  'a',\n",
       "  'crofitt',\n",
       "  'd√©l',\n",
       "  'Sur',\n",
       "  '(Andr√©s',\n",
       "  'y',\n",
       "  'compa√±√≠a',\n",
       "  'abrazo'],\n",
       " ['Gracias', 'y', 'Feliz', 'navidad', 'para', 'todos'],\n",
       " ['Feliz', 'Navidad', 'Sure√±os'],\n",
       " ['Hay',\n",
       "  'alg√∫n',\n",
       "  'problema',\n",
       "  'con',\n",
       "  'la',\n",
       "  'app',\n",
       "  'que',\n",
       "  'aparece',\n",
       "  '‚Äúhorarios',\n",
       "  'no',\n",
       "  'disponibles‚Äù?'],\n",
       " ['Despegada', 'atleta', '\\u200d'],\n",
       " ['No',\n",
       "  'importa',\n",
       "  'd√≥nde,',\n",
       "  'el',\n",
       "  '√©xito',\n",
       "  'est√°',\n",
       "  'asegurado,',\n",
       "  'porque',\n",
       "  'son',\n",
       "  'un',\n",
       "  'GRAN',\n",
       "  'equipo,',\n",
       "  'se',\n",
       "  've',\n",
       "  'reflejado',\n",
       "  'en',\n",
       "  'lo',\n",
       "  'que',\n",
       "  'han',\n",
       "  'logrado',\n",
       "  'y',\n",
       "  'en',\n",
       "  'todo',\n",
       "  'lo',\n",
       "  'especial',\n",
       "  'que',\n",
       "  'nos',\n",
       "  'brindan.',\n",
       "  'A',\n",
       "  'TODOS',\n",
       "  'gracias,',\n",
       "  'porque',\n",
       "  'as√≠',\n",
       "  'junto',\n",
       "  'a',\n",
       "  'ustedes',\n",
       "  'es',\n",
       "  'todo',\n",
       "  'm√°s',\n",
       "  'f√°cil.',\n",
       "  'Con',\n",
       "  'los',\n",
       "  'sure√±os',\n",
       "  'se',\n",
       "  'pasa',\n",
       "  'excelente',\n",
       "  'donde',\n",
       "  'sea',\n",
       "  'Tremenda',\n",
       "  'es',\n",
       "  'la',\n",
       "  'energ√≠a'],\n",
       " ['Siempre', 'sure√±os'],\n",
       " ['Con',\n",
       "  'alegr√≠a',\n",
       "  'Disfrutando',\n",
       "  'de',\n",
       "  'entrenar',\n",
       "  'al',\n",
       "  'aire',\n",
       "  'libre',\n",
       "  'y',\n",
       "  'de',\n",
       "  'lo',\n",
       "  'nuevo,',\n",
       "  'con',\n",
       "  'la',\n",
       "  'misma',\n",
       "  'gente',\n",
       "  'linda'],\n",
       " ['Genia', 'Siempre', 'con', 'la', 'mejor', 'energ√≠a'],\n",
       " ['Vaamooos', 'la', 'bandaa'],\n",
       " ['Esta', 'genial', 'entrenar', 'as√≠', 'Lindo', 'WOD', 'ü§¶\\u200d']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9c9ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'amor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-98634642a0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBabelSenticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mconcept_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mpolarity_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpolarity_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/senticnet/senticnet.py\u001b[0m in \u001b[0;36mconcept\u001b[0;34m(self, concept)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"polarity_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"polarity_value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/senticnet/senticnet.py\u001b[0m in \u001b[0;36mpolarity_label\u001b[0;34m(self, concept)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         \u001b[0mconcept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mconcept_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcept_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'amor'"
     ]
    }
   ],
   "source": [
    "from senticnet.senticnet import SenticNet\n",
    "\n",
    "sn = SenticNet()\n",
    "concept_info = sn.concept('love')\n",
    "polarity_label = sn.polarity_label('love')\n",
    "polarity_value = sn.polarity_value('love')\n",
    "moodtags = sn.moodtags('love')\n",
    "semantics = sn.semantics('love')\n",
    "sentics = sn.sentics('love')\n",
    "\n",
    "from senticnet.babelsenticnet import BabelSenticNet\n",
    "\n",
    "bsn = BabelSenticNet('pt')\n",
    "concept_info = sn.concept('amor')\n",
    "polarity_label = sn.polarity_label('amor')\n",
    "polarity_value = sn.polarity_value('amor')\n",
    "moodtags = sn.moodtags('amor')\n",
    "semantics = sn.semantics('amor')\n",
    "sentics = sn.sentics('amor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05e049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
